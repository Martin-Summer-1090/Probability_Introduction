---
bibliography: references.bib
---


# Random Variables

Random variables are the main mathematical tools that allow us to 
quantify and analyze uncertainty in Finance for complex
portfolios and other financial contexts like risk management and
In all of these contexts
random variables provide the foundation for probabilistic reasoning.

Throughout the previous lectures, we have encountered concepts such as 
conditional probabilities, dependencies, 
and independence. These ideas have helped us build intuition 
for modeling uncertainty. However, as we move 
into more advanced applications like portfolio risk modeling 
and asset price dynamics, a more explicit 
and formal treatment of **random variables** becomes unavoidable. 

Random variables are at the core of probability theory, serving as a bridge 
between real-world phenomena 
and mathematical models. They allow us to represent uncertain 
outcomes numerically and provide a 
framework for analyzing those outcomes using tools such 
as **expected value**, **variance**, and **covariance**. 
These measures are indispensable for understanding and managing financial risk.
Random variables play a vital role in applications like:

- **Portfolio Management**: Estimating the expected return and risk of a portfolio.
- **Risk Assessment**: Modeling the probability of extreme events, such as market crashes.
- **Asset Pricing**: Understanding how prices evolve over time using models like the binomial tree.

By the end of this lecture, you will:

1. Understand the definition and properties of random variables.
2. Learn how to compute and interpret expected value, variance, and covariance.
3. Apply R programming to simulate random variables and analyze financial scenarios.
4. Construct a binomial tree to model asset price dynamics.

## Random Variables and Distributions

A **random variable** is a numerical outcome of a random phenomenon. 
Formally, a random variable is a function 
that assigns a real number to each outcome in the sample space 
of a random experiment. More explicitly:

::: {.callout-tip title="Definition: Random Variable" #random-variable}
A **random variable** $X$ is a function
$X:\mathcal{S} \to \mathbb{R}$ from the sample space 
(the set of all possible outcomes of the random experiment) to
the real numbers.
:::

A random variable is thus a **function** defined
on the sample space of a random experiment.
This formal definition allows us to generalize and analyze a wide variety of 
real-world scenarios. For instance:

- In the coin-flipping example from Lecture 2, the number 
of heads in 10 flips was a random variable.
- The number of multiple brithdays in a group of $n$ people
is also an example of a random variable.

By explicitly recognizing these as random variables, we 
can now apply a systematic framework to quantify their behavior and 
analyze them.

Note that it is a widely held convention in probability theory
to use capital letters such as $X$ and $Y$ etc. as symbols of 
a random variable.

Random variables come in two varieties, depending on the
properties of the sample space ${\cal S}$. If the sample
space is a finite or countably finite set, the sample space
is discrete and we talk of a **discrete random variables**.

Sometimes it is natural to consider continuous sample spaces. For
example when we consider the return of an asset over a year or
the price of a stock at a specific time. In this
case we call a random variable **continuous**. With continuous sample
spaces we will need tools from calculus. We will discuss 
continuous random
variables in the next lecture. Here we stick with the
concept of a discrete random variable.

In the case of a discrete sample space we can theoretically 
tabulate and random variable $X$ by enumerating in some
order all points in the sample space and associating with
each the corresponding value of $X$.

## Probability Distributions and Cumulative Probability Distributions

A random variable is characterized by its **probability distribution**, which 
describes how probabilities are assigned to its possible values.

::: {.callout-tip title="Definition: Probability Mass Function of a Discrete Random Variable" #pmf-discrete}
Let $X$ be a random variable and $x_1, x_2, ...$ the values which it
assumes. The aggregate of all sample points on which $X$ assumes
a fixed value $x_i$ is form the event $X = x_i$. It's
probability is denoted by $P(X = x_i)$. The function:
\begin{equation*}
P(X = x_i) = p(x_i), \,\, i=1,2,...
\end{equation*}
is called the **probability distribution** of the random variable $X$.

where $p(x_i)$ satisfies:

- $0 \leq p(x_i) \leq 1 \,\, \text{for}\,\, i = 1,2, ...$
- $\sum_{i} p(x_i) = 1$.
:::

We can visualize the probability distribution of
a discrete random variable using R in a standard example:
Consider a random variable $X$ that represents the outcome of 
rolling a fair six-sided die. The probability distribution is:
$P(X = x_i) = \frac{1}{6}, \quad i = 1, 2, 3, 4, 5, 6$.

This can be visualized as:

```{r pmf-visualization}

# Plot bars

plot(1:6, rep(1/6,6), type = "h", 
        main = "Probability Distribution", 
        xlab = "Outcome", 
        ylab = "Probability")

# Add blue filled points at the top of each bar

points(1:6, rep(1/6, 6), pch = 16, col = "blue")
```

This plot shows that each outcome has an equal probability of $\frac{1}{6}$
symbolized as a bar. For better readability of the graph we symbolized the
function values at $1/6$ by a blue filled dot. 

Let me discuss some common confusions that arise often with understanding the
concept of a random variable.

1. **Random Variable vs. Outcome**: A random variable is not the same 
as an individual outcome. It is a function that assigns values to outcomes.
The confusion is partially created by the name. Maybe a better term would
be a random mapping. Anyway, keep in mind that a random variable is a 
function defined on the sample space.

2. **Probability Distribution vs. Histogram**: A probability distribution 
represents theoretical probabilities. Don't mix this concept up with
the concept of a histogram, known from statistics and data analysis, which 
shows frequencies of empirical data.

3. **Discrete vs. Continuous**: Discrete variables take 
specific values (e.g., dice outcomes), while continuous variables 
can take any value in a range. Dealing with continuous variables
needs specifc tools which we discuss in lecture 5.

::: {.callout-note title="Now You Try: Other Examples"}
Think of scenarios where you could define a discrete random variable. 

For instance:

- The number of defective products in a batch of 20.
- The number of rainy days in a week.

Simulate and visualize the Probability
distribution of these examples in R. You can take
the visualization approach we took here. You could
also try to make use of R's `barplot()` function.
:::

A related concept to the probability mass function (PMF), is the
**cumulative distribution function** (CDF). It can also be used to
describe a discrete random variable. The CDF provides the probability that 
the random variable $X$ takes a value less than or equal to a specific 
value $x$:

::: {.callout-tip title="Definition: Cumulative Distribution Function (CDF)" #cdf-discrete}
The **cumulative distribution function** - abbreviated CDF - shows 
the probability that a 
random variable $X$ take a value less than or equal to a given 
value $x_i$. It is usually denoted as $F(x_i) = P(X \leq x_i)$ 
where $F$ is non-decreasing and $0 \leq F(x_i) \leq 1$ for $i = 1,2,...$
:::

In the case of a discrete random variable the cumulative distribution function
(CDF) is a step function, increasing by jump discontinuities. The points where
the jumps occur are exactly at the values the random variable can take.

The CDF, $F(x)$, can be computed in this case as:

- $F(1) = P(X \leq 1) = P(X = 1) = \frac{1}{6}$,
- $F(2) = P(X \leq 2) = P(X = 1) + P(X = 2) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6}$,
- $F(3) = P(X \leq 3) = \frac{3}{6}$,
- ...
- $F(6) = P(X \leq 6) = \frac{6}{6} = 1$.

The CDF can be visualized as a step function, showing the cumulative probabilities:

```{r cdf-visualization}
x <- 1:6
cdf <- cumsum(rep(1/6, 6))

# Plot the empty plot frame
plot(0:6, c(0, cdf), type = "n", 
     main = "Cumulative Distribution Function", 
     xlab = "Outcome", 
     ylab = "F(x)", 
     xlim = c(0, 6.5), ylim = c(0, 1))

# Draw the first horizontal bar
segments(0, 0, 1, 0, col = "blue", lwd = 2)
points(0, 0, pch = 16, col = "blue")  # Closed circle at (0, 0)
points(1, 0, pch = 1, col = "blue", cex = 1.2)  # Open circle at (1, 0)

# Draw the stepwise CDF
for (i in 1:(length(x) - 1)) {
  # Draw the horizontal bar for each step
  segments(x[i], cdf[i], x[i + 1], cdf[i], col = "blue", lwd = 2)
  
  # Add the closed circle at the start of the segment
  points(x[i], cdf[i], pch = 16, col = "blue")  # Filled circle
  
  # Add the open circle at the end of the segment
  points(x[i + 1], cdf[i], pch = 1, col = "blue", cex = 1.2)  # Open circle
}

# Draw the last horizontal bar and closed circle at the end
segments(6, cdf[6], 6.5, cdf[6], col = "blue", lwd = 2)
points(6, cdf[6], pch = 16, col = "blue")  # Closed circle at (6, 1)

```

::: {.callout-tip}
## A Remark on Constructing Complex Graphs in R

This visualization of the cumulative distribution function (CDF) is a great example of how graphs in R can be constructed step by step using layers and overlays. Let's break it down to understand how the graph is built:

We start with a blank canvas and create an empty plot frame using `plot()` with `type = "n"`. The `type = "n"` argument ensures that no points or lines are drawn initially, allowing us to control exactly what is added to the plot later. This blank canvas defines the axes, labels, and range, providing a foundation for the layers to come.

The first horizontal line is drawn using `segments()`, starting from `(0, 0)` to `(1, 0)`. We add a filled circle (`pch = 16`) at the start `(0, 0)` and an open circle (`pch = 1`) at the end `(1, 0)` using `points()`. This step visually initializes the CDF at the correct starting point.

Each step of the CDF is added one at a time using a loop. For each step:
- A horizontal line is drawn to represent the constant value of the CDF over that interval.
- A closed circle is placed at the beginning of the line to indicate that the value is included in the CDF at that point.
- An open circle is added at the end to show that the value is not included yet, highlighting the jump discontinuity.

The final horizontal line is added separately to show the end of the CDF. A closed circle is placed at the end of the last step to signify the inclusion of the final value in the distribution.
:::


Here are some key points to keep in mind when working with cumulative 
distribution functions (CDFs):

- The CDF gives cumulative probabilities ($P(X \leq x)$), not individual 
probabilities.
- The CDF is always non-decreasing and reaches 1 for the largest 
possible value of $X$.
- The CDF for discrete variables is a step-function with jumps at the
values the random variable can take.

The concepts of a probability distribution function and cumulative 
distribution function (CDF) can be extended to more than one random variable. 
When working with multiple random variables, we are often interested in 
their **joint distribution**, which describes how they behave 
together, and **conditional distributions**, which describe how 
one variable behaves given specific information about another.
I discuss here the generalization to two random
variables. All of the following discussion generalizes
to more than two random variables.

::: {.callout-tip title="Joint Probability Mass Function" #joint-pmf-discrete}

Consider now two discrete random variables $X$ and $Y$ defined on the
same sample space. and let $x_1,x_2, ...$ and $y_1,y_2,...$ the values
which they assume. Let $f(x_i)$ and $g(y_j)$ be the corresponding
distribution functions. The aggregate of points in which the two condistions
$X=x_i$ and $Y=y_j$ are satisfied forms an event whose probability is 
denoted by
$$P(X = x_i, Y = y_j) = p(x_i, y_j), \,\, i,j,=1,2,...$$
is called the **joint probability distribution** of $X$ and $Y$.
where $p(x_i, y_j)$ satisfies:

- $0 \leq p(x_i, y_j) \leq 1$ for $i,j = 1,2, ...$,
- $\sum_{i,j} p(x_i, y_j) = 1$ for $i,j=1,2,...$..
:::

Let me give an example:
Imagine rolling two fair six-sided dice. Let $X$ and $Y$ represent 
the outcomes of the first and second dice, respectively. The joint PMF is:
$$P(X = x_i, Y = y_j) = \frac{1}{36}, \quad x_i, y_j = 1, 2, 3, 4, 5, 6.$$

This joint probability distribution 
captures the probability of every possible pair of outcomes, 
such as $(X = 2, Y = 5)$.

One visualization tool for two dimensional probability
sirtibutionsis the **heatmap**. The $x$ and $y$ axis
of the heat map symbolized the values of $X$ and $Y$ whereas the third dimension 
visualizes the probability of each pair of values $(x_i,y_j)$ by a color code. 
So, for
example when the dice are fair we should have a probability of $1/36$ for each
basic outcome, so you should see only one uniform color. 

To illustrate
this visualization concept, imagine an example where the dice are
biased and not fair, so the probabilities of outcomes can differ:


```{r}
# Define the outcomes and probabilities for two biased dice
outcomes <- 1:6
prob_die1 <- c(0.05, 0.1, 0.2, 0.25, 0.2, 0.2)  # Probabilities for die 1
prob_die2 <- c(0.1, 0.15, 0.2, 0.25, 0.2, 0.1)  # Probabilities for die 2

# Compute the joint PMF as the outer product of the two probability vectors
joint_pmf <- outer(prob_die1, prob_die2)

# Create a heatmap using the image() function
image(
  1:6, 1:6, joint_pmf,
  col = colorRampPalette(c("white", "blue"))(100),
  xlab = "Outcome of Die 2",
  ylab = "Outcome of Die 1",
  main = "Heatmap of Joint PMF (Two Biased Dice)",
  axes = FALSE
)

# Add axis labels
axis(1, at = 1:6, labels = outcomes)
axis(2, at = 1:6, labels = outcomes)

# Add a color legend
legend(
  "topright", 
  legend = round(seq(min(joint_pmf), max(joint_pmf), length.out = 5), 3),
  fill = colorRampPalette(c("white", "blue"))(5),
  title = "Probability"
)


```

Here you see immediately that something is fishy with the dice.
Would the dice be fair there should be a uniform color all over the
heatmap with a color at the value of $1/36$ or $0.03$. Try it!


With this notation we can also define the notion of
a conditional probability for discrete random
variables.

::: {.callout-tip title="Definition: Conditional Probability"}
The **conditional probability** of an event $Y=y_j$, given
$X=x_i$ with $f(x_i) > 0$ is defined as
$$
P(Y = y_j | X = x_i) = \frac{p(x_i,y_j)}{f(x_i)}
$$
:::

In this way a number is associated with every value of $X$ and so 
defines a function on $X$. This function is called

::: {.callout-tip title="Definition: Conditional Distribution"}

The **conditional distribution** of $Y$ for given $X$ and
denoted by
$$
P(Y = y_j|X)
$$
:::

Let's note a few improtant points about conditional distributions:

1. In general, the conditional probability distribution of $Y$ given $X = x_i$ (denoted $p(y_j \mid x_i)$) 
differs from the marginal probability distribution $g(y_j)$. This means that 
knowing the value of $X$ provides information about $Y$, which indicates 
stochastic dependence between $X$ and $Y$. The strongest form of dependence 
occurs when $Y$ is a deterministic function of $X$, i.e., $Y = h(X)$ for some 
function $h$. In this case, $X$ completely determines $Y$, and 
their relationship is entirely predictable.

On the other hand, if the joint probability distribution $p(x_i, y_j)$ factorizes as:
$$
p(x_i, y_j) = f(x_i) g(y_j) \quad \text{for all pairs } (x_i, y_j),
$$
then $X$ and $Y$ are **independent**. This implies that the occurrence of one
event (e.g., $X = x_i$) has no influence on the probability of the 
other (e.g., $Y = y_j$). The joint distribution in this case takes the form 
of a multiplication table, where the probabilities are products of the marginal 
probabilities. When $X$ and $Y$ are independent, their interaction is
minimal, and no inference can be drawn about one variable from the other.

2. The joint distribution $p(x_i, y_j)$ uniquely determines the 
marginal distributions $f(x_i)$ and $g(y_j)$, as these can be computed 
by summing over the appropriate dimensions:
$$
f(x_i) = \sum_j p(x_i, y_j), \quad g(y_j) = \sum_i p(x_i, y_j).
$$
However, the reverse is not true: the marginal 
distributions $f(x_i)$ and $g(y_j)$ alone do not determine 
the joint distribution $p(x_i, y_j)$. For example, different 
joint distributions can have the same marginals but encode 
different types of dependence or independence between $X$ and $Y$.

3. Note that two random variables $X$ and $Y$ can have the same marginal 
distribution $f(x_i) = g(y_j)$ but may or may not be independent. 
For instance:
- If $X$ and $Y$ are independent, their joint distribution will 
factorize as described earlier.
- If $X$ and $Y$ are dependent, their joint distribution will 
include nontrivial interactions between the variables.

For instance, consider $X$ and $Y$ that both represent the outcomes of 
rolling two fair dice. If $X$ and $Y$ are independent, the joint 
probabilities $p(x_i, y_j)$ will simply be products of the marginal 
probabilities. However, if $X = Y$ (e.g., the two dice always show 
the same value), the joint distribution will reflect perfect dependence, 
and $X$ and $Y$ are no longer independent despite having identical marginal 
distributions.

Here is a visualization of this situation:

```{r}
# Define a joint PMF for dependent dice: one die matches the other
outcomes <- 1:6
joint_pmf <- diag(1/6, 6, 6)  # Probability of matching outcomes is 1/6 for each pair

# Create heatmap for the dependent joint PMF
image(
  1:6, 1:6, joint_pmf,
  col = colorRampPalette(c("white", "blue"))(100),
  xlab = "Outcome of Die 2",
  ylab = "Outcome of Die 1",
  main = "Heatmap of Joint PMF (Dependent Dice)",
  axes = FALSE
)
axis(1, at = 1:6, labels = outcomes)
axis(2, at = 1:6, labels = outcomes)

# Add a color legend
legend(
  "topright",
  legend = round(seq(min(joint_pmf), max(joint_pmf), length.out = 5), 3),
  fill = colorRampPalette(c("white", "blue"))(5),
  title = "Probability"
)
```

Keep in mind:

- **Joint Distributions** describe how two random variables behave together.
- **Conditional Distributions** refine our understanding of one variable based on information about another.
-  Joint PMFs naturally generalize to describe both **independent** and **dependent** random variables. For dependent   variables, the joint PMF captures the interaction and dependencies between the variables, often requiring **conditional probabilities** to explain the relationships.
- These concepts are foundational for understanding dependencies 
in financial modeling, such as asset correlations or portfolio risk.

## Expected Value, Variance, Covariance

When working with random variables, we often need to summarize their 
behavior in a way that allows us to make decisions, compare outcomes, or 
model uncertainty. This is where the concepts of expected value, variance, 
and covariance come into play:

  - **Expected value** provides a measure of the central tendency of a random 
  variable, giving us a "weighted average" that reflects the most likely or 
  typical outcome over the long run. It allows us to predict the average result 
  in situations with uncertainty.

  - **Variance** and its square root, the **standard error**, quantify the spread 
  or variability of a random variable's outcomes. These measures are crucial
  for understanding risk in contexts like finance, where variability 
  often corresponds to uncertainty or volatility.

  - **Covariance** extends this idea to pairs of random variables, capturing how 
  changes in one variable are related to changes in another. This is 
  particularly important in portfolio theory, where understanding how asset 
  returns move together enables better diversification and risk management.

Together, these tools provide a mathematical framework for understanding, 
summarizing, and modeling uncertainty, making them indispensable 
in fields ranging from finance to engineering to data science.

So let us dive into the formal definitions.

### Expected Value

The **expected value** of a random variable is a summary 
measure 
that captures the central tendency of its distribution. It represents 
the long-run average value of the variable if the experiment is 
repeated many times.

::: {.callout-tip title="Definition: Expected Value" #expected-value-discrete}
The expected value $\mathrm{E}(X)$ of a discrete random variable $X$ is the 
probability-weighted sum of all its possible values:
$$
\mathrm{E}(X) = \sum_{i=1}^{n} x_i p(x_i),
$$
where $x_i$ are the possible values of $X$ and $p(x_i)$ are their associated 
probabilities.
:::

Note that for countably infinite outcomes, convergence conditions are 
required, but 
we focus on finite cases here.

As an example, consider a fair six-sided die. 
The possible outcomes are $\{1, 2, 3, 4, 5, 6\}$, each with 
probability $1/6$. The expected value is:

```{r}
# Expected value of a fair die

outcomes <- 1:6

probabilities <- rep(1/6, 6)

expected_value <- sum(outcomes * probabilities)

expected_value # output
```

Although the expected value is 3.5, this value will never actually occur 
in a single roll—it is a theoretical average that represents the 
long-term central tendency of the outcomes if the die is rolled repeatedly. 
In other words, the expected value is not necessarily a possible outcome but 
rather a weighted average that balances all possible outcomes according to 
their probabilities. This highlights a common misunderstanding: the expected 
value is not a prediction of what will happen in a single trial, but a 
summary of what we can expect over many repetitions of the experiment.

### Variance and Standard Error

While the expected value provides the central tendency, 
the **variance** measures the spread of a 
random variable around its expected
value.

::: {.callout-tip title="Definition: Variance" #variance-discrete}
The **variance** of $X$ is the expected value of the squared deviations 
from its expected value:
$$
\mathrm{Var}(X) = \mathrm{E}[(X - \mathrm{E}(X))^2].
$$
:::

For discrete random variables, this can be computed as:
$$
\mathrm{Var}(X) = \sum_{i=1}^{n} \left(x_i - \mathrm{E}(X)\right)^2 p(x_i).
$$

Using algebra, variance can also be written as:
$$
\mathrm{Var}(X) = \mathrm{E}[X^2] - (\mathrm{E}[X])^2.
$$


The **standard error** is the square root of the variance:
$$
\mathrm{SE}(X) = \sqrt{\mathrm{Var}(X)}.
$$
What is the advantage to think in terms of standard errors rather than in terms
of variance itself, when we think about the variability of a random
variable? To see why, suppose $X$ represents the **daily high temperature** 
in a specific city during the month of July, measured in **degrees Celsius ($^\circ C$)**. 
For simplicity, let's assume $X$ is modeled as a random variable with the 
following characteristics based on historical data:

1. **Mean (Expected Value)**:  
   The average high temperature in July is $\mathbb{E}(X) = 25 \,^\circ C$.

2. **Variance**:  
   The variance of daily high temperatures is:
   $$\mathrm{Var}(X) = 9 \, (\text{^\circ C}^2)$$.

   While mathematically meaningful, the variance is expressed in squared 
   degrees Celsius $^\circ C^2$, which is unintuitive. People 
   don't typically think about "squared temperature."

3. **Standard Error**:  
   Taking the square root of the variance gives:
   $$\mathrm{SE}(X) = \sqrt{\mathrm{Var}(X)} = \sqrt{9} = 3 \,^\circ C.$$
A variance of $9 \,^\circ C^2$ is difficult to relate to because we don't 
experience temperature in squared units. A standard error of $3 \,^\circ C$, 
however, 
directly informs us that the daily high temperature typically deviates from the 
average ($25 \,^\circ C$) by about $3 \,^\circ C$.

#### Example
Using the fair die example, calculate the variance and standard error:

```{r}
# Variance and standard deviation of a fair die
E_X_squared <- sum(outcomes^2 * probabilities)
variance <- E_X_squared - (expected_value^2)
std_dev <- sqrt(variance)

variance  # Output: 2.916667
std_dev   # Output: 1.707825
```

### Covariance

The **covariance** measures the linear relationship between two random variables. 

::: {.callout-tip title="Definition: Covariance" #covariance-discrete}
For two random variables $X$ and $Y$ their **covariance** is defined as
It is defined as:
$$
\mathrm{Cov}(X, Y) = \mathrm{E}[(X - \mathrm{E}(X))(Y - \mathrm{E}(Y))].
$$
:::

Alternatively:
$$
\mathrm{Cov}(X, Y) = \mathrm{E}[XY] - \mathrm{E}[X]\mathrm{E}[Y].
$$
If $X$ and $Y$ are independent, then $\mathrm{Cov}(X, Y) = 0$. However, the 
converse is not true: a covariance of 0 does not imply independence.

Example:
Consider two dice, $X$ and $Y$, rolled simultaneously. Let $X$ represent the outcome of the first die and $Y$ the second. If the dice are independent, the covariance is 0:

```{r}
# Covariance of two independent dice
joint_pmf <- outer(probabilities, probabilities)
E_XY <- sum(outcomes %*% t(outcomes) * joint_pmf)
covariance <- E_XY - (expected_value^2)
covariance  # Output: 0
```

Now, consider a scenario where $X$ and $Y$ are dependent but still have a 
covariance of 0. Let $X$ represent a random variable that takes the 
values $\{-1, 0, 1\}$, and let $Y$ be defined as $Y = X^2$. 
The joint distribution of $(X, Y)$ is as follows:

| $X$ |   $Y$     | Probability |
|--------|--------|-------------|
| -1     | 1      | $1/3$       |
|  0     | 0      | $1/3$       |
|  1     | 1      | $1/3$       |

The random variables $X$ and $Y$ are clearly dependent because $Y$ is fully 
determined by $X$. However, their covariance is 0. 
Check it!^[$\mathbb{E}(X) = (-1) \cdot \frac{1}{3} + 0 \cdot \frac{1}{3} + 1 \cdot \frac{1}{3} = 0$
$\mathbb{E}(Y) = 1 \cdot \frac{1}{3} + 0 \cdot \frac{1}{3} + 1 \cdot \frac{1}{3} = \frac{2}{3}$
$\mathbb{E}(XY) = (-1)(1) \cdot \frac{1}{3} + (0)(0) \cdot \frac{1}{3} + (1)(1) \cdot \frac{1}{3} = 0$
$\mathrm{Cov}(X, Y) = \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y) = 0 - (0 \cdot \frac{2}{3}) = 0$ Thus, $\mathrm{Cov}(X, Y) = 0$, even though $X$ and $Y$ are not independent]

This example highlights that while independence guarantees a covariance of 0, the reverse is not true.
The **correlation coefficient** normalizes the covariance to a dimensionless measure:
$$
\rho(X, Y) = \frac{\mathrm{Cov}(X, Y)}{\mathrm{SD}(X) \cdot \mathrm{SD}(Y)}.
$$
The correlation coefficient ranges from $-1$ (perfect negative correlation) to $1$ (perfect positive correlation).

What does it mean if covariance is called a **linear** measure of
dependence? Let me explain:
The **covariance** measures the degree to which two random variables 
change together, focusing specifically on their **linear relationship**. 
But what does it mean for the relationship to be linear, and what happens 
if the relationship is not linear?

A linear relationship implies that one random variable can 
be expressed approximately as a linear function of the other:

$$Y = aX + b$$

where $a$ and $b$ are constants. If two variables are positively linearly related, an increase in one variable tends to be associated with a proportional increase in the other. Conversely, if they are negatively linearly related, an increase in one variable tends to correspond to a proportional decrease in the other.

Covariance captures this pattern by examining how the deviations of $X$ and $Y$ from their respective means 
$(X - \mathbb{E}[X])$ and $(Y - \mathbb{E}[Y])$ vary together.

- A **positive covariance** indicates that larger values of $X$ are associated with larger values of $Y$.
- A **negative covariance** indicates that larger values of $X$ are associated with smaller values of $Y$.
- A **covariance near zero** suggests no linear relationship, though other forms of relationships might still exist.

Covariance is limited to linear relationships. If the dependence between 
two random variables is non-linear—such as quadratic, exponential, or 
periodic—covariance might be zero, even though the variables are strongly related.

For example:

- If $Y = X^2$, the relationship is perfectly deterministic. However, if 
$X$ is symmetrically distributed around zero the covariance could still be zero.
- For a sinusoidal relationship like $Y = \sin(X)$, covariance would also fail to capture the dependence.



### Intuition for Covariance
To understand covariance, think of it as quantifying how closely the relationship between two variables resembles a straight-line pattern. The stronger the alignment with a straight line (positive or negative slope), the larger the magnitude of the covariance. However, when the relationship follows a curve or more complex pattern, covariance might fail to reflect the dependence, and other tools may be needed.^[To detect and measure non-linear relationships, alternative statistical tools are required:
1. **Correlation Ratio $(\eta^2)$**: Measures the proportion of variance in one variable that can be explained by a non-linear function of the other.
2. **Mutual Information**: Captures all forms of dependencies (linear and non-linear) by quantifying the shared information between two random variables.
3. **Kendall's Tau / Spearman's Rank Correlation**: Rank-based measures that can detect monotonic (but not necessarily linear) relationships.
4. **Distance Correlation**: A measure capable of capturing both linear and non-linear relationships by analyzing distances between data points.]

### A Note on Terminology

Some of you might have wondered why I use distinct terminology like mean and
expected value or standard deviation and standard error. Why do I do this?

Let me explain:
In probability and statistics, certain terms are often used 
interchangeably, leading to potential confusion. To ensure 
clarity, we distinguish between **empirical measures**, which 
describe observed data, and **theoretical measures**, which 
describe properties of random variables and probability distributions.

In an empirical context, when working with data we speak of

- **Mean**: The arithmetic average of observed data points. It provides a 
measure of central tendency for the sample or population.
- **Standard Deviation**: A measure of the spread or variability of the 
observed data around the mean.

These quantities are calculated directly from data and are specific to 
the observed sample.

In a theoretical context, when we work with random variables and distributions we
speak of

- **Expected Value**: The theoretical long-run average of a random 
variable, derived from its probability distribution. It represents 
the "center" of the distribution in a probabilistic sense.

- **Standard Deviation**: The theoretical spread of a random variable’s values 
around its expected value, also derived from the probability distribution.

These measures rely on the underlying distribution of the random variable 
and are not directly observable. 

Why does this distinction matter?

1. **Clarity in Context**: Empirical measures describe what we observe, while theoretical measures describe the underlying process or model.
2. **Foundation for Inference**: Understanding the relationship between empirical and theoretical measures is key to making statistical inferences.
3. **Precision in Communication**: Using terms consistently helps avoid ambiguity in academic and professional discussions.

### Summary Table

| **Context**             | **Measure**            | **Term**              | **Definition/Role**                                                          |
|--------------------------|------------------------|------------------------|-------------------------------------------------------------------------------|
| **Empirical Data**       | Central Tendency      | Mean                  | The average of observed data points.                                          |
|                          | Spread                | Standard Deviation     | The dispersion of data points around the mean.                                |
| **Probability Distributions** | Central Tendency      | Expected Value         | The theoretical average of a random variable based on its probability distribution. |
|                          | Spread                | Standard Deviation     | The spread of a random variable's values around its expected value.           |
| **Sampling Distributions** | Spread of Estimate    | Standard Error         | The standard deviation of a sample statistic, indicating estimation precision. |

By maintaining this distinction, we connect the descriptive analysis of data with the theoretical underpinnings of probability and the tools of inferential statistics.


## Random Variables: Simulating Portfolio Returns with Discrete Outcomes

In this section, we build a simple portfolio simulation using discrete 
random variables to model asset returns. Based on this cas study
we will push the frontier of your R knowledge a bit further
giving you the tools to efficiently write more complex
programs in R.

This example demonstrates modular R programming, flow control s
tructures like `if-else` statements and loops, and the use 
of lists for organizing and processing data.

### Asset Returns: A Key Concept in Finance

Before we model investment problems using probability and random 
variables, let’s establish some essential financial concepts. 

In Finance, an **asset** refers to any investment instrument 
that can be bought or sold, such as stocks, bonds, real 
estate, or even a savings account. Assets are the 
building blocks of investment decisions.

When you invest in an asset, you expect to receive some form of 
payoff in the future. Let:

- $X_0$: The amount of money invested today.
- $X_1$: The amount received at a future time, say one year from now.

The **total return** ($R$) is the ratio of the amount received to the 
amount invested:
$$R = \frac{X_1}{X_0}$$

Often, practitioners refer to the **rate of return** ($r$), which 
measures the proportionate change in value:
$$r = \frac{X_1 - X_0}{X_0}$$

The two measures are closely related:
$$R = 1 + r \quad \text{or equivalently,} \quad X_1 = (1 + r) X_0$$

The rate of return ($r$) behaves similarly to an interest rate, describing 
the growth (or decline) of your investment relative to the initial outlay.

In many cases, the rate of return is not known in advance. For example:

- A stock's future price may depend on market conditions.
- A bond may carry the risk of default, affecting its final payoff.
- Real estate returns depend on fluctuating property values and rental income.

This uncertainty in returns is a fundamental aspect of investment. 
To analyze it rigorously, we model rates of 
return as **random variables**.

Random variables provide a mathematical framework for capturing uncertainty. 
For instance:

- $X_1$, the future payoff of an asset, is modeled as a random variable 
because its value depends on uncertain factors.
- Since $R = \frac{X_1}{X_0}$ and $r = \frac{X_1 - X_0}{X_0}$, both 
the total return ($R$) and rate of return ($r$) are also random variables.

Modeling returns as random variables allows us to:

1. **Describe the range of possible outcomes**: For example, $X_1$ could 
be high, low, or anywhere in between.
2. **Quantify likelihoods**: We assign probabilities to outcomes, such 
as a 20% chance of a large gain or a 5% chance of a significant loss.
3. **Analyze investment risk and reward**: Using tools like expected value, 
variance, and covariance, we can measure and manage the trade-off between 
risk and return.

### Analyzing Returns with Discrete and Continuous Models

In this lecture, we focus on **discrete models**, where the possible outcomes 
of returns are finite and can be explicitly listed. For example, a stock 
might have three possible states—high, medium, or low returns—with 
assigned probabilities. Continuous models, where returns can 
take any value within a range, will be introduced in the next lecture.

### Portfolio Setup

We model the returns of three assets using discrete random variables. 
Each asset has three possible returns, and their joint outcomes 
are determined by a random 
state (e.g., economic scenarios: "High", "Medium", "Low"). 
These states have associated probabilities.

Where do these probabilities come from?
In probability theory, probabilities are treated as fundamental 
quantities, much like length or area in geometry. They are 
simply "given" and form the foundation for analyzing uncertainty. 
For example, we might assume that the probability of 
a "High" economic scenario is 30%, while "Medium" and "Low" 
scenarios occur with probabilities of 50% and 20%, respectively.

However, in practical applications, these probabilities are 
rarely known a priori. Assigning probabilities to real-world events is 
a complex task that often requires the use of data and statistical models. 
In Finance, this is the domain of econometrics and related disciplines. 

For instance:

- Historical data on market conditions might be analyzed to estimate the 
likelihood of different economic scenarios.
- Expert judgment or forecasts (e.g., from central banks or financial analysts) 
might supplement data to refine these probabilities.
- Bayesian methods can combine prior beliefs with new data to 
update probabilities dynamically.

In our example, we assume the probabilities are already known to 
focus on understanding how probability theory can be applied to 
investment problems. This assumption simplifies the analysis and 
allows us to explore key concepts like expected value and variance 
without the added complexity of estimating probabilities.

It’s important to recognize that the choice of probabilities—whether 
derived from data, expert judgment, or theoretical models—directly 
influences the results of any analysis. In real-world applications, 
the validity of conclusions often hinges on how well these probabilities 
capture the underlying uncertainties.

So let us start our example by first defining 
asset returns and probabilities using R:

```{r asset-returns-and-probabilities-portfolio-example}

# Define states and their probabilities

states <- c("High", "Medium", "Low")
probabilities <- c(0.3, 0.5, 0.2)  # Must sum to 1

# Define asset returns for each state

asset_returns <- list(
  asset_1 = c(0.08, 0.04, -0.02), # Returns for Asset 1
  asset_2 = c(0.12, 0.03, -0.05), # Returns for Asset 2
  asset_3 = c(0.05, 0.02, 0.01)   # Returns for Asset 3
)

```


### Writing Modular Functions

To model portfolio returns, we break the problem into smaller tasks and write 
modular functions. This approach makes the code more manageable, reusable, 
and easier to debug. Modularizing your code is a principle
you should follow always when writing smaller or larger
programs. One strategy how this can be done is 
breaking down a bigger task into smaller ones and 
implement the smaller tasks as functions.

In our case where we want to implement a
portfolio simulation we need:

1. Simulate a Random State
2. Get the Asset Returen for each state
3. Compute the portfolio returns
4. Simulate portfolio performance

Let me go through these steps function by function.

#### Simulate a Random State

We begin by simulating a random economic 
state (e.g., "High," "Medium," or "Low") based on the 
probabilities assigned to each state.

```{r simulate-states}
simulate_state <- function(states, probabilities) {
  sample(states, size = 1, replace = TRUE, prob = probabilities)
}
```

The `simulate_state` function uses R’s `sample()` function to randomly 
choose one of the states based on their respective probabilities.
This is a tool you already know. I do not have to say much more
on the sample function. 

As a remark, observe that it is a good idea to give to your
functions names that you or somebody can easily understand. A good
approach is to think in verbs, what is the function doing? When
you need more than one word an often used convention in
coding is to use and underscore to connect words.

Our function is constructed such that it can take any finite state
vector and any given state probabilities as input.

#### Get Asset Returns for a State

Once a state is selected, we retrieve the corresponding returns 
for each asset. To accomplish this, we use the flexibility and 
power of R’s **list** structure.

Let us recall the list structure which we have touched only
very briefly in previous lectures.

A **list** in R is a data structure that can hold multiple 
objects of different types and lengths. Lists are highly 
versatile, making them particularly useful for functional 
programming. For example, you can store vectors, matrices, 
data frames, and even other lists within a single list.

Here’s an example of creating and accessing a list:

```{r creating-a-list-example}
# Create a list

my_list <- list(
  vector = c(1, 2, 3),
  matrix = matrix(1:4, nrow = 2),
  data_frame = data.frame(a = 1:2, b = 3:4)
)

# Access elements of the list

my_list$vector   # By name
my_list[[2]]     # By position
my_list[["matrix"]] # Equivalent to my_list[[2]]
```

Lists allow you to organize related but heterogeneous data in a structured way. 
For example, in our case, the returns for each asset are stored 
as individual vectors within a list, where each vector corresponds to one asset.

Lists are particularly advantageous in programming because of their:

1. **Flexibility**: They can hold objects of different types and sizes, making 
them a universal container.
2. **Indexing**: Elements can be accessed using names or positions, 
enabling both clarity and adaptability.
3. **Extensibility**: Lists can easily grow or change in structure 
without altering the overall program logic.
4. **Integration with Functions**: R functions like `lapply`, `sapply`, and `map` 
are designed to work seamlessly with lists, promoting concise and efficient code.

The `get_returns` function uses a list (`asset_returns`) to store 
the possible returns for each asset across states. Here’s the function:

```{r get_returns_function}
get_returns <- function(state, states, asset_returns) {
  index <- which(states == state)
  sapply(asset_returns, `[`, index)
}
```

Let’s break it down step by step:

1. **Input Arguments**:

   - `state`: The randomly chosen state (e.g., "High").
   - `states`: A vector of all possible states (e.g., `c("High", "Medium", "Low")`).
   - `asset_returns`: A list where each element is a vector of returns
                      for an asset, corresponding to each state.

2. **Find the Index of the State**:

The `which` function finds the position of the selected 
state within the `states` vector:

`index <- which(states == state)`

For example, if `state = "Medium"` and `states = c("High", "Medium", "Low")`,
the result will be `index = 2`.

3. **Extract Returns Using `sapply`**:

The `sapply` function applies the
subsetting operator `[` to each element of the `asset_returns` list:

`sapply(asset_returns, `[`, index)`

   - `sapply(asset_returns, ...)` iterates over each element of the list.
   -  The operator `[`, with `index` as the argument, extracts the value at 
   the `index` position from each vector in the list.

   For example, if:

`asset_returns <- list(
     asset_1 = c(0.08, 0.04, -0.02),
     asset_2 = c(0.12, 0.03, -0.05),
     asset_3 = c(0.05, 0.02, 0.01)
   )`
   
   and `index = 2`, the result will be:

`c(asset_1 = 0.04, asset_2 = 0.03, asset_3 = 0.02)`

The `sapply` function is part of a family of functions in R designed for
iterating over elements of lists (or other objects like vectors). These
functions enable you to apply a specified operation to each element of a
list in a concise and readable way. This approach often replaces
traditional `for` loops and promotes a functional programming style.

`sapply()`is one member of a family of R's functions written for
operations on lists.

Here’s an overview of the main functions in this family:

1. **`lapply`**:

Applies a function to each element of a list and returns a list of the results. It is
useful when the output needs to remain as a list.

Example:

```{r}
my_list <- list(a = 1:3, b = 4:6, c = 7:9)
lapply(my_list, sum)
```

2. **`sapply`**: A simplified version of `lapply` that attempts to return
results as a vector or matrix, if possible.
If simplification isn’t feasible, it falls back to returning a list.

Example:

```{r}
my_list <- list(a = 1:3, b = 4:6, c = 7:9)
sapply(my_list, sum)
```


3. **`vapply`**: Similar to `sapply`, but requires you to specify the type
of the returned result (e.g., numeric, character).
Useful for ensuring type consistency and avoiding unexpected results.

Example:

```{r}
vapply(my_list, sum, numeric(1))
```

4. **`tapply`**: Applies a function to subsets of a vector, grouped by a
factor or factors. It is a very powerful workhorses for data analysis,
commonly used for grouped computations.

Example:

```{r}
   x <- c(1, 2, 3, 4, 5, 6)
   groups <- factor(c("A", "A", "B", "B", "C", "C"))
   tapply(x, groups, sum)
```

5. **`mapply`**:

A multivariate version of `sapply`, allowing iteration over multiple inputs
simultaneously.

Example:

```{r}
   x <- 1:3
   y <- 4:6
   mapply(sum, x, y)
```

So why Use `sapply` in our example?

The `sapply` function is well-suited for our example because:
1. The `asset_returns` object is a **list**, where each element corresponds to
the returns of a single asset.
2. We want to extract a single value (the return for a given state)
from each list element.
3. `sapply` simplifies the output into a named vector, making it
easier to use for further computations.

Let’s revisit the `get_returns` function:

```{r}
get_returns <- function(state, states, asset_returns) {
  index <- which(states == state)  # Find the index of the selected state
  sapply(asset_returns, `[`, index)  # Extract the return for the state from each asset
}
```

`sapply(asset_returns, \`[\`, index)` applies the subsetting operator (`[`) to each element of the `asset_returns` list, using `index` as the argument. The result is a named vector of returns
for the specified state, with names corresponding to the assets.

By understanding `sapply` and its related functions, you gain access to powerful
tools for working with lists and other data structures in R. These functions
are essential for writing efficient, modular, and readable R code.

#### Compute Portfolio Return

The portfolio return is calculated as the weighted sum of the individual
asset returns.

```{r}
compute_portfolio_return <- function(weights, returns) {
  sum(weights * returns)
}
```

This function multiplies each asset’s return by its respective weight and
sums the result, yielding the total portfolio return.

#### Putting Everything Together: Simulate Portfolio Performance

We now combine the functions we created earlier into a larger
function, `simulate_portfolio`, that simulates portfolio performance
over multiple time periods. Each simulation’s results are stored
in a **list**, leveraging modularity for clarity and reusability.
Modular code makes it easier to debug, document, and extend.

R provides several ways to iterate over data, with **for-loops** being
a fundamental and widely used method. In a for-loop, R sequentially
applies the specified code to each element of a sequence or range.

Here’s a basic example of a for-loop in R:

```{r}
# Example of a simple for-loop
for (i in 1:5) {
  print(i)
}
```

For-loops are intuitive and work well for many tasks. However, when
iterating over larger datasets, it’s important to write efficient loops.
One key best practice is **preallocating space** for the output of the loop.
Without preallocation, R has to repeatedly resize the output object, which
can slow down the computation significantly.

In our `simulate_portfolio` function, we preallocate space for
the results using `vector("list", n_periods)`. This creates
a list of length `n_periods` before entering the loop. Preallocation
ensures that each iteration simply fills an existing slot in the list,
avoiding costly memory reallocation.

Here’s how it looks in our function:

```{r simulate-portfolio-function}

simulate_portfolio <- function(n_periods, weights, states, probabilities, asset_returns) {

  # Preallocate space for the results
  results <- vector("list", n_periods)

  for (i in 1:n_periods) {
    # Simulate a random state
    state <- simulate_state(states, probabilities)

    # Retrieve the returns for the selected state
    returns <- get_returns(state, states, asset_returns)

    # Compute the portfolio return
    portfolio_return <- compute_portfolio_return(weights, returns)

    # Store the results for this iteration in the preallocated list
    results[[i]] <- list(
      state = state,
      returns = returns,
      portfolio_return = portfolio_return
    )
  }

  results
}
```

In R, for-loops and lists are often used together but serve distinct purposes:
- **For-loops**: Provide a mechanism for iterating over elements or ranges, applying code to each iteration step. They are versatile and easy to understand but can become slow without preallocation for large datasets.
- **Lists**: Offer a flexible data structure for storing diverse types of output (e.g., vectors, data frames, or even other lists). They work well with for-loops when preallocated and are essential for modular code and functional programming.

In our example, the for-loop performs the iteration
over `n_periods`, while the list (`results`) stores the output for
each period. This combination strikes a balance between simplicity and efficiency.

Let me unpack the `simulate_portfolio`function a bit further.

The `simulate_portfolio` function runs a simulation for `n_periods`.
Each iteration:

1. Simulates a random state using `simulate_state`.
2. Retrieves the returns for all assets in that state using `get_returns`.
3. Computes the portfolio return using `compute_portfolio_return`.
4. Stores the results (state, returns, portfolio return) in the preallocated `results` list.

The function returns a list where each element contains:

- **The random state**: The economic scenario for the period.
- **The asset returns**: A named vector of returns for each asset.
- **The portfolio return**: The weighted average return for the portfolio.

Here’s an example of what the output might look like for a single simulation:

```{r}
# Output for one period
list(
  state = "Medium",
  returns = c(asset_1 = 0.04, asset_2 = 0.03, asset_3 = 0.02),
  portfolio_return = 0.032
)
```

By preallocating space and combining modular functions, this approach ensures
efficient and readable code, while also allowing students to explore each step
of the simulation in isolation or as part of the larger process.


This refined section introduces iteration concepts, explains the
importance of preallocation, and highlights the synergy between for-loops and lists. Let me know if you’d like further enhancements!

We now define the portfolio weights, which must sum to 1. This says that we have
invested 50 % of our wealth into asset 1, 30 % into asset 2 and 20 % into
asset 3.

```{r}
weights <- c(0.5, 0.3, 0.2)  # Weights for the three assets
```

We can now simulate the portfolio performance over
any numebr of periods using the functions we created.
Let#s say we do a simulation for 1000 periods.

```{r}
set.seed(42)  # For reproducibility
n_periods <- 1000

simulation_results <- simulate_portfolio(n_periods, weights, states, probabilities, asset_returns)
```

Now we have a huge pile of data stored in an object with the name `simulated_results`. What
do we do with this?

We extract the portfolio returns from the simulation and
compute summary statistics such as the mean and variance of the returns.

```{r}
# Extract portfolio returns

portfolio_returns <- sapply(simulation_results, `[[`, "portfolio_return")

# Compute summary statistics

mean_return <- mean(portfolio_returns)
variance_return <- var(portfolio_returns)

list(mean = mean_return, variance = variance_return)
```

Here we have summarized the distribution of our random variables using the
concepts we learned before, thereby documenting their average return and thus
the average return of the portfolio as well as how spread out these returns
are.

We can also create a histogram to visualize the
full distribution of the simulated portfolio returns.

```{r}
hist(portfolio_returns, breaks = 3, main = "Portfolio Returns", xlab = "Return")
```

Let us explore the list structure we have chosen here to demonstarte how it
helps us to access simulation details.

Each element of simulation_results is itself a list, containing:

- The random state.
- The returns for each asset in that state.
- The computed portfolio return.

For example, to inspect the first simulation we would
type

```{r}
simulation_results[[1]]
```

Let us also compute state frequencies to check whether our random
number generator has actually implemented what we have given him
in terms of probabilities as arguments to the `sample()`function.

```{r}
state_counts <- table(sapply(simulation_results, `[[`, "state"))
state_frequencies <- prop.table(state_counts)
state_frequencies
```

Here’s the refined passage with the formula and explanation added:

---

Finally, we can compare the results of our simulation to key statistics of the portfolio, such as the **expected portfolio return**. These statistics can also be computed theoretically using the definitions of expected value and portfolio return.

The **expected return** of each asset is calculated as:
$$E(r^i) = \sum_{j=1}^m p_j \cdot r^i_j$$
where:

- $r^i_j$ is the return of asset $i$ in state $j$,
- $p_j$ is the probability of state $j$,
- $m$ is the total number of states.

The **expected portfolio return** is then the weighted sum of the expected
returns of the individual assets:
$$E(R_{\text{portfolio}}) = \sum_{i=1}^n w^i \cdot E(r^i)$$
where:

- $w^i$ is the weight of asset $i$ in the portfolio,
- $n$ is the total number of assets.

The following R code computes the expected portfolio return using the formulas above:

```{r expected return}
# Compute expected returns for each asset
expected_returns <- sapply(asset_returns, function(asset) sum(asset * probabilities))

# Compute the expected portfolio return
expected_portfolio_return <- sum(weights * expected_returns)

# Display the result
expected_portfolio_return
```

Let me unpack this a bit:

1. **Expected Returns of Individual Assets**:

- The `sapply` function iterates over the `asset_returns` list, which contains the returns for each asset across the states.
- For each asset, it computes the weighted sum of its returns using the probabilities of the states:

`sum(asset * probabilities)`

This corresponds directly to the formula $E(r^i) = \sum_{j=1}^m p_j \cdot r^i_j$.

2. **Expected Portfolio Return**:

- The `weights` vector contains the portfolio allocation for each asset.
- The `sum(weights * expected_returns)` computation takes the weighted sum of the expected returns of the individual assets:

`sum(weights * expected_returns)`

This corresponds to the formula $E(R_{\text{portfolio}}) = \sum_{i=1}^n w^i \cdot E(r^i)$.

By computing these values theoretically, we can validate the results of our
simulation and gain confidence in both our simulation setup and the
mathematical underpinnings of portfolio theory.

::: {.callout-note title="Now You Try"}
Now that we’ve calculated the **expected portfolio return** both theoretically and through simulation, take the next step and compute the **theoretical variance** of the portfolio.

Recall the formula for the variance of a portfolio:
$$
\text{Var}(R_{\text{portfolio}}) = \sum_{i=1}^n (w^i)^2 \cdot \text{Var}(r^i) + \sum_{i \neq j} w^i \cdot w^j \cdot \text{Cov}(r^i, r^j)
$$
where:
- $\text{Var}(r^i) = \sum_{j=1}^m p_j \cdot (r^i_j - E(r^i))^2$ is the variance of asset $i$,
- $\text{Cov}(r^i, r^j) = \sum_{j=1}^m p_j \cdot (r^i_j - E(r^i)) \cdot (r^j_j - E(r^j))$ is the covariance between assets $i$ and $j$.

### Steps to Get Started
1. **Compute the Variance of Each Asset**:
   Use the formula for variance to calculate $\text{Var}(r^i)$ for each asset based on the `asset_returns` and `probabilities`.

2. **Compute the Covariance Between Pairs of Assets**:
   Calculate $\text{Cov}(r^i, r^j)$ for all pairs of assets.

3. **Combine Variances and Covariances**:
   Use the portfolio weights and the formula above to compute $\text{Var}(R_{\text{portfolio}})$.

### Tips
- Use `sapply` to efficiently compute variances and covariances across assets.
- Store the covariance values in a matrix for easier calculations.

Once you’ve completed the theoretical calculations, compare the theoretical portfolio variance to the variance obtained from your simulation. Does it match? What could explain any differences?

:::


Here’s a refined and streamlined version of the section, with improved structure, clarity, and flow, while keeping the main content intact. I also adjusted some arguments to improve accuracy and teaching focus:

---

## The Binomial Distribution and its role in Finance

In this final section, we explore the **binomial distribution**, a 
discrete distribution with significant applications in Finance. It 
forms the foundation for one of the most important models of asset p
rice dynamics: **binomial lattices**. This discussion not only 
deepens our understanding of probability but also introduces 
tools in R to work with parametric distributions.

### Bernoulli and Binomial Random Variables

#### Bernoulli Random Variable: The Building Block

A **Bernoulli experiment** has two possible outcomes, commonly 
labeled as "success" and "failure." The corresponding **Bernoulli random variable** takes 
a value of 1 for success and 0 for failure, with a success probability $p$ and failure probability 
$1-p$. 

If $X \sim \text{Bernoulli}(p)$, then:
- $E(X) = p$(expected value),
- $\text{Var}(X) = p(1-p)$ (variance).

Try deriving these properties from the definitions of expectation and variance!

#### Binomial Random Variable: Extending the Bernoulli

The **binomial random variable** is the sum of $n$ independent Bernoulli 
random variables, modeling the total number of successes in $n$ trials. 
If $X \sim \text{Binomial}(n, p)$, then:
- $E(X) = n \cdot p$,
- $\text{Var}(X) = n \cdot p \cdot (1-p)$.

The probability of exactly $k$ successes is given by:
$$P(X = k) = \binom{n}{k} p^k (1-p)^{n-k},$$
where $\binom{n}{k} = \frac{n!}{k!(n-k)!}$ is the **binomial coefficient**.

#### Intuition Through an Example

Let’s consider rolling a fair die five times, with success defined as 
rolling a six. The number of sixes follows a binomial distribution 
with $n = 5$ and $p = 1/6$. Here’s how we compute probabilities:

- **All Sixes** ($X = 5$):  
  $P(X = 5) = (1/6)^5$.  

```{r}
  (1/6)^5
```

- **No Sixes** ($X = 0$):  
  $P(X = 0) = (5/6)^5$.  

```{r}
  (5/6)^5
```

- **Exactly One Six** ($X = 1$):  
  $P(X = 1) = 5 \cdot (5/6)^4 \cdot (1/6)$.  

```{r}
  5 * (5/6)^4 * (1/6)
```

### Working with the Binomial Distribution in R

R provides built-in functions for parametric distributions. For the binomial distribution:
1. `dbinom(x, n, p)`: Probability $P(X = x)$.
2. `pbinom(x, n, p)`: Cumulative probability $P(X \leq x)$.
3. `rbinom(N, n, p)`: Generate $N$ random samples from a binomial distribution.
4. `qbinom(r, n, p)`: Quantile function.

#### Simulating and Comparing Approaches

To illustrate, let’s simulate rolling a die five times 
and compare it with the binomial model:

```{r}
# Custom simulation

roll_die_five <- function() {
  res <- sample(1:6, 5, replace = TRUE)
  sum(res == 6)
}

# Simulate 100,000 trials

sim_rolls <- replicate(10^5, roll_die_five())

# Binomial distribution simulation

sim_roll_with_rbinom <- rbinom(10^5, 5, 1/6)
```

Plot the distributions and compare:

```{r}
# Plot histogram for custom simulation

hist(sim_rolls, 
     breaks = seq(-0.5, max(sim_rolls) + 0.5, by = 1), 
     main = "Custom Simulation", 
     xlab = "Number of Sixes", 
     col = "lightblue", 
     border = "black")

# Plot histogram for rbinom simulation

hist(sim_roll_with_rbinom, 
     breaks = seq(-0.5, max(sim_roll_with_rbinom) + 0.5, by = 1), 
     main = "R's rbinom Function", 
     xlab = "Number of Sixes", 
     col = "lightgreen", 
     border = "black")

```

---

### Modeling Asset Price Dynamics with Binomial Trees

#### Real-World Asset Price Dynamics

In practice, asset prices fluctuate due to market forces, 
dividends, interest rates, and other uncertainties. **Binomial trees** 
are a powerful and simple way to model these dynamics over time. Unlike 
single-period models, binomial trees capture the evolution of prices 
across multiple periods.

#### Constructing the Binomial Model

For a basic period (e.g., a day), assume:

- The price can either increase by a factor $u$ or decrease by a factor $d$.
- The probabilities of up and down movements are $p$ and $1-p$.

If the initial price is $S_0$, then after $n$ periods:
$$S_n = S_0 \cdot u^i \cdot d^{n-i},$$
where $i$ is the number of up movements.

#### Calibrating the Model

Given annualized return ($\nu$) and volatility ($\sigma$), we set:
$$u = e^{\sigma \sqrt{\Delta t}}, \quad d = e^{-\sigma \sqrt{\Delta t}}, \quad p = \frac{1}{2} + \frac{\nu}{2\sigma} \sqrt{\Delta t},$$
where $\Delta t$ is the fraction of a year (e.g., 1/250 for daily).

#### Building the Binomial Tree in R

Here’s a function to generate a binomial tree:

```{r}

binomial_tree <- function(S0, up, down, steps) {
  tree <- matrix(0, nrow = steps + 1, ncol = steps + 1)
  for (i in 1:(steps + 1)) {
    for (j in 1:i) {
      tree[i, j] <- S0 * up^(j - 1) * down^((i - 1) - (j - 1))
    }
  }
  return(tree)
}
```

Test the function with three steps:

```{r}

tree <- binomial_tree(S0 = 100, up = 1.1, down = 0.9, steps = 3)
tree
```

#### Simulating SP500 Prices

Using historical SP500 data, calculate:
- $\nu$: Average annual log return.
- $\sigma$: Annualized volatility.

Then, simulate the binomial price process and visualize the probability
distribution of final prices:

we need to work this out still using concrete returns.

<!-- ```{r} -->
<!-- # Simulate a year of daily prices -->
<!-- tree <- binomial_tree(S0 = 100, up = u, down = d, steps = 250) -->
<!-- outcomes <- tree[dim(tree)[1], ] -->
<!-- plot(outcomes, dbinom(0:250, size = 250, prob = p), type = "h") -->
<!-- ``` -->

### Subsection: Leveraging an LLM to Enhance Learning from Binomial Models

#### **Using an LLM for Advanced Financial Modeling**

An LLM like ChatGPT can significantly enhance your learning experience from this lecture by helping you:
1. **Understand Complex Concepts**: Get detailed explanations of topics like binomial trees, asset price dynamics, and probability distributions.
2. **Generate Customized Code**: Create tailored R scripts to experiment with different stocks, time horizons, or assumptions.
3. **Validate Your Work**: Debug your code or verify theoretical calculations.
4. **Extend the Model**: Explore advanced variations, such as incorporating dividends or multi-asset portfolios.

---

#### Using an LLM to enhance you understanding: Debugging and Extending the Binomial Tree Model

Imagine you’ve written an R function to generate a binomial tree but are unsure if the logic is correct. You can ask the LLM to review your code, explain its functionality, and suggest improvements.

For example:
**Prompt to the LLM**:

> "I wrote this function to generate a binomial tree in R. Can you check if it’s correct? If not, how can I fix it?"
```r
binomial_tree <- function(S0, up, down, steps) {
  tree <- matrix(0, nrow = steps + 1, ncol = steps + 1)
  for (i in 1:(steps + 1)) {
    for (j in 1:i) {
      tree[i, j] <- S0 * up^(j - 1) * down^((i - 1) - (j - 1))
    }
  }
  return(tree)
}
```

The LLM can:
- Analyze the logic and verify the implementation.
- Suggest optimizations, like avoiding redundant calculations.
- Explain how to test the function with sample inputs and interpret the results.

---

#### **Use Case: Generating Advanced Visualizations**

You want to visualize not just the final outcomes of the binomial model but also the entire tree structure over time. While this isn’t covered in the lecture, you can ask:
> "How can I visualize the full binomial tree structure generated by my function?"

The LLM can suggest:
- Using packages like `DiagrammeR` or `igraph` for structured visualizations.
- Overlaying probabilities or expected values on the tree for deeper insights.

---

#### **Use Case: Customizing the Project**

You’ve completed the project but want to explore additional scenarios. For example:
- Use different assets (e.g., cryptocurrencies or ETFs).
- Model dividends or transaction costs.
- Extend the tree to multiple assets for portfolio modeling.

**Prompt to the LLM**:
> "How can I extend my binomial tree model to include transaction costs of 0.1% for every price change?"

The LLM can guide you step-by-step:
1. Modify the price calculation at each node to subtract transaction costs.
2. Adjust the recursion logic to account for the modified prices.
3. Validate the results and interpret the impact of transaction costs.

---

#### **Why This Matters**

Using an LLM allows you to:
- Gain insights beyond the lecture material.
- Accelerate your coding and problem-solving skills.
- Explore advanced scenarios without requiring pre-existing expertise.

By leveraging these tools effectively, you can turn theoretical concepts into practical, actionable skills that prepare you for real-world challenges in Finance and beyond.

---

Would you like this subsection expanded or tailored further to specific aspects of the lecture?

### Project Proposal: Simulating and Analyzing Real-World Asset Price Dynamics with Binomial Trees

#### **Objective**
Create a project where students use **real-world stock price data** (retrieved via `tidyquant`) to:
1. Build a **binomial tree model** for a selected stock’s price dynamics.
2. Calibrate the model using historical data (e.g., average annual return and volatility).
3. Simulate the stock's potential price distribution over a defined time horizon.
4. Analyze and visualize the results to compare simulated outcomes with theoretical values.

This project ties together the lecture’s concepts, emphasizes practical applications, and encourages exploration of real data.

### **Step-by-Step Structure for the Project**

#### **Step 1: Data Retrieval**
1. Use the `tidyquant` package to download historical stock price data for a user-selected stock (e.g., "AAPL" or "MSFT").
2. Compute **daily log returns** and **annualized statistics**:
   - Average annual log return (\( \nu \)).
   - Annualized volatility (\( \sigma \)).

#### Example Code:

```{r}
library(tidyquant)
library(tidyverse)

# Retrieve historical stock prices
stock_data <- tq_get("AAPL", from = "2018-01-01", to = "2023-01-01")

# Compute daily log returns
stock_data <- stock_data %>%
  mutate(log_return = log(adjusted / lag(adjusted)))

# Annualized statistics
nu <- mean(stock_data$log_return, na.rm = TRUE) * 252
sigma <- sd(stock_data$log_return, na.rm = TRUE) * sqrt(252)

nu
sigma
```

#### **Step 2: Calibrate the Binomial Tree Parameters**

1. Define the time step as daily ($\Delta t = 1/252$).
2. Compute the **up factor** ($ u $), **down factor** ($ d $), and **probability** ($p$) using the formulas:
   - $u = e^{\sigma \sqrt{\Delta t}}$
   - $d = e^{-\sigma \sqrt{\Delta t}}$
   - $p = \frac{1}{2} + \frac{\nu}{2\sigma} \sqrt{\Delta t}$.

#### Example Code:

```{r}
delta_t <- 1 / 252
u <- exp(sigma * sqrt(delta_t))
d <- exp(-sigma * sqrt(delta_t))
p <- 0.5 + (nu / (2 * sigma)) * sqrt(delta_t)

u
d
p
```

#### **Step 3: Build the Binomial Tree**

1. Write a function to generate a binomial tree for a given stock.
2. Use the calibrated parameters to simulate the stock price evolution over a given horizon (e.g., 1 year with 252 steps).

#### Example Code:

```{r}
binomial_tree <- function(S0, u, d, p, steps) {
  tree <- matrix(0, nrow = steps + 1, ncol = steps + 1)
  
  for (i in 1:(steps + 1)) {
    for (j in 1:i) {
      tree[i, j] <- S0 * u^(j - 1) * d^((i - 1) - (j - 1))
    }
  }
  
  tree
}

# Generate a binomial tree for 1 year
S0 <- 100  # Starting stock price
tree <- binomial_tree(S0, u, d, p, steps = 252)
```

---

#### **Step 4: Simulate and Visualize Final Price Distribution**

1. Extract the last row of the binomial tree to analyze final stock price outcomes.
2. Use the **binomial distribution** to compute the probabilities for each outcome.
3. Plot the **probability mass function (PMF)** and compare it to the simulated distribution.

#### Example Code:

```{r}
# Extract final prices and probabilities
final_prices <- tree[dim(tree)[1], ]
probabilities <- dbinom(0:252, size = 252, prob = p)

# Plot PMF
plot(final_prices, probabilities, type = "h", 
     main = "Probability Mass Function", 
     xlab = "Final Stock Price", ylab = "Probability")
```

---

#### **Step 5: Comparison and Analysis**
1. Compare the expected value of the final stock price from the model to the expected value based on the annualized return.
2. Discuss discrepancies and assumptions (e.g., independence of returns, constant volatility).


### **Deliverables**
1. **Code Implementation**: A complete script that retrieves data, calibrates the model, builds the binomial tree, and visualizes the results.
2. **Report**:
   - Explanation of the binomial model and its calibration.
   - Interpretation of the results (e.g., insights from the PMF, expected value, etc.).
   - Reflection on the limitations of the model and suggestions for improvement.

---

### **Why This Project?**
- **Practical Relevance**: Students work with real data, gaining insights into real-world financial modeling.
- **Integration of Concepts**: Combines probability, binomial distributions, asset price dynamics, and R programming.
- **Exploration Opportunities**: Students can tweak parameters, test different stocks, or extend the model (e.g., incorporating dividends or multi-asset portfolios).

Would you like me to expand any section or provide additional example code?