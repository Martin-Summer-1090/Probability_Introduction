# The Concept of Conditional Probability

To appreciate the significance of conditional probability, let us start with a simple but striking scenario from the world of finance. Imagine you are an investor trying to evaluate the safety of a bond portfolio. On paper, the bonds are rated highly by reputable agencies, and the portfolio looks diversified—a dream investment. However, during a global recession, a few defaults occur, and to your surprise, the entire portfolio begins to unravel, causing significant losses. How could this happen?

This seemingly safe portfolio turned risky because it underestimated the connections between events—a core idea tied to conditional probability. Conditional probability helps us analyze how the risk of one event changes given another has occurred. It enables us to model dependencies, a critical factor in real-world scenarios, particularly during financial crises.

Understanding these relationships isn't just an intellectual exercise—it’s crucial for preventing catastrophic losses. Whether you're pricing complex financial instruments, assessing credit risk, or making investment decisions, mastering conditional probability allows you to account for interconnected risks and avoid misleading conclusions based on oversimplified assumptions.

More generally conditional probability is the key instrument of probability theory that guides you in adjusting risk assessment when new information becomes available that was not there before.

With this motivation in mind, we now turn to a historical example that demonstrates the importance of understanding conditional probability: the financial crisis of 2007-2008. This crisis revealed how wrong assumptions about independence and neglect of dependence in events and conditional probabilities can lead to systemic failures in structured finance.^[ See @Tooze2018: For an engaging and comprehensive exploration of the financial crisis and its causes . It is highly recommended for deeper study.]

## Understanding Structured Finance: Bonds, Pools, and Tranches

Let us begin with a simplified overview of the basic ideas of structured finance and the engineering of specific risk profiles from a portfolio of risky bonds. This example will then illustrate all the basic ideas of conditional probability motivating our more formal discussion later.

### Bonds and Credit Risk

**Bond, face value, par value** : A **bond** is a financial instrument where the issuer agrees to pay the holder a specific amount, the **face value** or **par value**, at maturity. Bonds are widely used as fixed-income securities but carry the risk of default if the issuer faces financial difficulties.

To quantify this risk, bonds are rated by agencies such as Moody’s and Standard & Poor’s. Investment-grade bonds are considered low-risk, while speculative or "junk" bonds are riskier and more likely to default. Here is a summary of their rating schemes and what the ratings mean in words:

| Rating Category   | Moody's | Standard & Poor's |
| ----------------- | ------- | ----------------- |
| High grade        | Aaa     | AAA               |
|                   | Aa      | AA                |
| Medium grade      | A       | A                 |
|                   | Baa     | BBB               |
| Speculative grade | Ba      | BB                |
|                   | B       | B                 |
| Default danger    | Caa     | CCC               |
|                   | Ca      | CC                |
|                   | C       | C                 |
|                   |         | D                 |

### Pooling and Tranching: The Innovation

Structured finance emerged in the early 2000s as a way to manage risk through **pooling** and **tranching**. By pooling risky assets and dividing cash flows into "tranches" with distinct risk profiles, financial engineers created new bonds, including investment-grade securities, from portfolios of junk bonds. A major product of this innovation was the **mortgage-backed security (MBS)**.

#### An Illustrative Example: Building Structured Finance in Steps

Let us develop an intuitive understanding of structured finance through incremental steps. This approach allows us to see how independence and assumptions were critical in shaping these financial instruments.

##### Step 1: A Simple Event Tree for One Bond

Consider a single bond that pays €1 at maturity. This bond has a 10% chance of default, meaning there is a 90% chance it will not default. With a default probability of 10%, this bond would likely receive a speculative grade rating, such as 'B' or 'B-' in the rating tables presented earlier. This poor rating reflects the significant risk of non-payment associated with such a bond, which could deter risk-averse investors and highlight its 'junk' bond status. The payoff is structured as follows:

- If the bond does not default (“N”), the payoff is €1.
- If the bond defaults (“D”), the payoff is €0.

This situation can be represented as a simple probability tree:

To help visualize this tree, we will use the `DiagrammeR` package in R, which simplifies the creation of diagrams without requiring deep graphing expertise. This approach reinforces concepts you’ve already learned, such as loading and working with R packages.

First, we load the package:

```{r}
library(DiagrammeR)
```

Next, we create a simple tree to represent the outcomes for a single bond:

```{r}
grViz("\
  digraph one_bond_tree {
    rankdir=LR;
    node [shape=circle, style=filled, fillcolor=lightblue];

    A [label='t=0']
    B1 [label='No Default
(P=0.9)']
    B2 [label='Default
(P=0.1)']

    A -> B1
    A -> B2
  }
")
```

This code defines the nodes (events at each stage) and edges (probabilities of transitions) in the tree. The `rankdir=LR` option specifies a left-to-right layout. The output clearly shows the two possible outcomes for the bond, along with their probabilities.

Finally, execute the code in R to render the diagram and observe how the tree visually represents the potential outcomes of the bond.

```{r one-stage-tree, echo=FALSE, out.width='90%', fig.align='center'}
knitr::include_graphics('figures/one_bond_tree.png')
```

##### Step 2: Combining Two Bonds with an Independence Assumption

Now consider two identical bonds, each with a 10% default probability. Assuming the defaults are independent, the joint probability distribution can be visualized in a two-stage event tree:

- The likelihood of both bonds not defaulting is \(P(B^1_N \cap B^2_N) = P(B^1_N) \cdot P(B^2_N) = 0.9 \cdot 0.9 = 0.81\).
- The likelihood of one bond defaulting while the other does not is \(0.9 \cdot 0.1 + 0.1 \cdot 0.9 = 0.18\).
- The likelihood of both bonds defaulting is \(0.1 \cdot 0.1 = 0.01\).

The two-stage event tree reflects these probabilities:

```{r two-stage-tree, echo=FALSE, out.width='90%', fig.align='center'}
knitr::include_graphics('figures/double_tree_two_bonds.png')
```

##### Step 3: Pooling and Tranching

The next step involves pooling the cash flows of these two bonds and dividing them into two new securities:

1. **Investment-grade bond (I):** Defaults only if both original bonds default. Thus, \(P(I\,\text{default}) = 0.01\).
2. **Junk bond (J):** Pays only if neither bond defaults, making it riskier. \(P(J\,\text{default}) = 0.99\).

By creating these tranches, structured finance transforms two junk bonds into one investment-grade bond and one highly risky bond. This reallocation of risk creates the illusion of reduced overall portfolio risk.

##### Why Independence Matters

The above transformations hinge critically on the assumption of **independence**. Without it, the probabilities of joint defaults would increase, undermining the ratings of the newly created investment-grade bonds.

Professionals at the time often justified their reliance on the independence assumption by pointing to historical data and diversification principles. However, these assumptions failed during systemic crises when defaults became highly correlated, exposing the fragile foundations of structured finance.

### The Pitfall of Dependent Risks

Structured finance relies heavily on the assumption of **independence**. But in reality, defaults are often correlated, especially during systemic crises. For instance, a recession might increase the likelihood of multiple defaults simultaneously, invalidating the independence assumption.

```{r dependent-risks, out.width='90%', fig.align='center', fig.cap='An event tree for dependent default probabilities', echo=FALSE}
knitr::include_graphics('figures/dependence.png')
```

Under dependence, the probability of joint defaults increases, eroding the reliability of investment-grade ratings. This matters because investors and institutions, relying on these flawed ratings, underestimated the risk embedded in these securities. As defaults started to cluster during the financial crisis, losses quickly cascaded through the financial system. The assumed independence between risks provided a false sense of security, which led to over-leveraging and an inability to hedge adequately against systemic failures. Ultimately, this misjudgment amplified the scale and speed of the crisis, exposing the financial system’s vulnerability to correlated risks.

### Lessons from Structured Finance

The structured finance example underscores the need for precise reasoning about conditional probabilities and independence. These concepts are not just abstract mathematical ideas—they have profound implications for real-world decision-making.

## Bayes' Theorem: Updating Beliefs with New Information

Bayes' theorem allows us to update probabilities based on new evidence systematically. It not only provides a mechanism for incorporating new data but also addresses a critical question in probability theory: how do we connect frequencies with single-event probabilities?

### Formal Definition

**Bayes' Theorem** : Let \$A\$ and \$B\$ be two events with \$P(B) > 0\$. Bayes' theorem states: \\begin{equation\*} P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)} \\end{equation\*}

This formula bridges the gap between the frequentist interpretation of probability (long-run frequencies) and the Bayesian view (degrees of belief).

### Frequency and Probability: Closing the Gap

The weak law of large numbers shows that frequencies converge to probabilities over many trials. However, it does not address how to interpret single-event probabilities. Bayes' theorem provides this connection by allowing us to infer probabilities in light of observed frequencies.

Consider the structured finance example: observing mortgage delinquencies enables us to update the likelihood of bond defaults, moving from long-term averages to actionable probabilities.

### Example 1: "Where Is the Speck?"

Imagine inspecting a camera lens for a speck of dust. Initially, the speck’s location is equally likely on the front lens, rear lens, or not on the lens at all. After observing a smudge on a test image, we update our beliefs using Bayes' theorem.

```{r}
# Define prior probabilities
prior <- c(front = 1/3, rear = 1/3, none = 1/3)

# Define likelihoods
likelihood <- c(front = 0.9, rear = 0.7, none = 0.1)

# Compute unnormalized posteriors
unnormalized <- prior * likelihood

# Normalize to get posterior probabilities
posterior <- unnormalized / sum(unnormalized)
posterior
```

### Example 2: Overconfidence in Financial Risk Assessment

Overconfidence in structured finance often led to underestimating correlated risks. Bayesian updating can reveal the pitfalls of such optimism. Let’s streamline the R example:

```{r}
# Define initial assumptions
prior <- c(independent = 0.9, dependent = 0.1)

# Define likelihoods of observed defaults under each scenario
likelihood <- c(independent = 0.05, dependent = 0.2)

# Compute unnormalized posteriors
unnormalized <- prior * likelihood

# Normalize to get posterior probabilities
posterior <- unnormalized / sum(unnormalized)
posterior
```

### Visualization

To visualize the updating process for the "Where Is the Speck?" example:

```{r}
# Ensure prior and posterior are explicitly defined and have consistent lengths
prior <- c(front = 1/3, rear = 1/3, none = 1/3)
posterior <- c(front = 0.45, rear = 0.35, none = 0.2) # Example values consistent with prior

# Create the data frame
scenarios <- data.frame(
  Scenario = rep(c("Prior", "Posterior"), each = 3),
  Location = rep(c("Front", "Rear", "None"), 2),
  Probability = c(prior, posterior)
)

# Visualization
library(ggplot2)
ggplot(scenarios, aes(x = Location, y = Probability, fill = Scenario)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Bayesian Updating: Speck Location", x = "Location", y = "Probability")
```


